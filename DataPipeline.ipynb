{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a1fa15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5677876",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f41c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CommonInf(Introduction, ds):\n",
    "    #Common information\n",
    "    string = \"\"\"\n",
    "    {}\n",
    "    \n",
    "    Common information:\n",
    "    Head:\n",
    "    {}\n",
    "    \n",
    "    Null values:\n",
    "    {}\n",
    "    \n",
    "    Row size:\n",
    "    {}\n",
    "        \"\"\".format(Introduction, ds.head(5), ds.isnull().sum(), ds.shape[0] )\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9c4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NanValues(ds):\n",
    "    #Verify how many null rows there are in the ds doesnt matter the column\n",
    "    NullValues = ds.isnull().sum().sum()\n",
    "    \n",
    "    #Validation about null values\n",
    "    if(NullValues > 0):\n",
    "        return ds.dropna()\n",
    "    else:\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53fd56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateFormat(ds):\n",
    "    ds['DateSales']= pd.to_datetime(ds['DateSales'])\n",
    "    #Casting the dateSales column with the standart date format yyyy/mm/dd\n",
    "    ds['DateSales'] = ds['DateSales'].dt.strftime('%Y/%m/%d')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd383b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CategoricalRow(ds):\n",
    "    #Factorizing the model column in order to have a different number per category\n",
    "    ds['Model'] = pd.factorize(ds['Model'])[0] \n",
    "    return pd.DataFrame(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e7d005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YearSale(ds):\n",
    "    #Cast to datetime the datesales column\n",
    "    ds['DateSales']= pd.to_datetime(ds['DateSales'])\n",
    "    #Extracting only the year in a new column called year sale\n",
    "    ds['Year Sale'] = ds['DateSales'].dt.strftime('%Y')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddb68985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoubletoInt(ds):\n",
    "    #Cast only the year column to int type\n",
    "    ds['year'] = ds['year'].astype(int)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8880afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractAndTransform():\n",
    "    ds = pd.read_csv('dataset.csv')\n",
    "    print(CommonInf('Initial dataset', ds))\n",
    "    \n",
    "    #Validation for nan values\n",
    "    ds = NanValues(ds)\n",
    "    print(CommonInf('Dataset after null validation',ds))\n",
    "    \n",
    "    #Validation for standart date format yyyy/mm/dd\n",
    "    ds = dateFormat(ds)\n",
    "    \n",
    "    #Year of sale\n",
    "    ds = YearSale(ds)\n",
    "    \n",
    "    #Converting model to numeric values\n",
    "    ds = CategoricalRow(ds)\n",
    "    \n",
    "    #Casting year column from double to int\n",
    "    ds= DoubletoInt(ds)\n",
    "    \n",
    "    print('Dataframe to insert:')\n",
    "    print(ds.head(5))\n",
    "    \n",
    "    #return de final dataframe\n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30c44a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreatingTable(tableName, cursor):\n",
    "    sql = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {}(\n",
    "            ID INT PRIMARY KEY,\n",
    "            CAR VARCHAR NOT NULL,\n",
    "            MODEL VARCHAR NOT NULL,\n",
    "            VIN VARCHAR NOT NULL,\n",
    "            YEAR INT NOT NULL,\n",
    "            DATESALES DATE NOT NULL,\n",
    "            ADDRESS VARCHAR NOT NULL,\n",
    "            YEARSALE INT NOT NULL\n",
    "        );\n",
    "    \"\"\".format(tableName)\n",
    "    cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54db5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InsertingData(df, tableName, engine):\n",
    "    #Write the dataframe in append mode to avoid delete previous data\n",
    "    df.to_sql(tableName, engine, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00eb4163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadingData(cursor, tableName):\n",
    "    #Reading 10 rows\n",
    "    print('Final insert review')\n",
    "    cursor.execute('select * from {} limit 10;'.format(tableName))\n",
    "    for i in cursor.fetchall():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e4b2f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InsertInPostgresql(df,User, Password, Host, Database, Port, tableName):\n",
    "    # establish connections\n",
    "    conn_string = 'postgresql://{}:{}@{}/{}'.format(User, Password, Host, Database)\n",
    "    engine = sqlalchemy.create_engine(conn_string)\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        database=Database,\n",
    "        user=User, \n",
    "        password=Password, \n",
    "        host=Host\n",
    "    )\n",
    "  \n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    #Principal function to create the table if it isn't exist\n",
    "    CreatingTable(tableName, cursor)\n",
    "    \n",
    "    #Principal function to insert the dataframe in the table\n",
    "    InsertingData(df, tableName, engine)\n",
    "    \n",
    "    #Function to read the data from postgresql table\n",
    "    ReadingData(cursor, tableName)\n",
    "    \n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abf9da9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 'Volkswagen', 0, '19UUA66285A189929', 2010, datetime.datetime(2013, 9, 10, 0, 0), 'PO Box 48548', '2013')\n",
      "(2, 3, 'Ford', 1, '1G6YX36D365936025', 1995, datetime.datetime(2006, 10, 22, 0, 0), 'Suite 36', '2006')\n",
      "(3, 4, 'Audi', 2, 'WBAPK53569A461317', 2000, datetime.datetime(2005, 2, 18, 0, 0), 'PO Box 75995', '2005')\n",
      "(5, 6, 'Chevrolet', 3, '1GKS1HE0XBR157468', 1993, datetime.datetime(2011, 7, 28, 0, 0), 'PO Box 27981', '2011')\n",
      "(6, 7, 'Mitsubishi', 4, 'WAUKH78E67A197316', 2000, datetime.datetime(2017, 8, 22, 0, 0), 'Suite 78', '2017')\n",
      "(7, 8, 'Honda', 5, 'WAUKH98EX8A221632', 2004, datetime.datetime(2000, 6, 11, 0, 0), 'Apt 1865', '2000')\n",
      "(8, 9, 'BMW', 6, '5J8TB3H52DL731513', 1996, datetime.datetime(2010, 8, 25, 0, 0), 'PO Box 34840', '2010')\n",
      "(10, 11, 'GMC', 7, 'WBA3B9C5XEJ747672', 2011, datetime.datetime(2001, 10, 14, 0, 0), 'PO Box 67445', '2001')\n",
      "(11, 12, 'Dodge', 8, 'WBSCL93491L186329', 1994, datetime.datetime(2007, 12, 6, 0, 0), 'Room 824', '2007')\n",
      "(13, 14, 'Pontiac', 9, '3GYFNAE38FS191313', 2006, datetime.datetime(2009, 12, 6, 0, 0), 'PO Box 46426', '2009')\n"
     ]
    }
   ],
   "source": [
    "#Main function\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #Main variables \n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--User\", required= True, help= \"User in postgresql Database\")\n",
    "    ap.add_argument(\"--Pass\", required= True, help= \"User's Password\")\n",
    "    ap.add_argument(\"--Host\", required= True, help= \"Principal host\")\n",
    "    ap.add_argument(\"--Db\", required= True, help= \"Database sink\")\n",
    "    ap.add_argument(\"--Port\", required= True, help= \"Port\")\n",
    "    ap.add_argument(\"--Table\", required= True, help= \"Table name\")\n",
    "    \n",
    "    args = vars(ap.parse_args())\n",
    "    \n",
    "    User = args['User']\n",
    "    Password=args['Pass']\n",
    "    Host=args['Host']\n",
    "    Database=args['Db']\n",
    "    Port=int(args['Port'])\n",
    "    TableName=args['Table']\n",
    "\n",
    "    df = ExtractAndTransform()\n",
    "    try:\n",
    "        InsertInPostgresql(df,User, Password, Host, Database, Port ,TableName)\n",
    "    except Exception as e: \n",
    "        print('Error: {}'.format(e))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
